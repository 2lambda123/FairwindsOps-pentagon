#!/usr/bin/env python

import os
import pentagon
import sys
import click
import subprocess
import jinja2
import datetime
import shutil
import string
import logging

from git import Repo, Git
from shutil import copytree, ignore_patterns
from Crypto.PublicKey import RSA


class PentagonException(Exception):
    """Exception raised for errors in the input.
    Attributes:
        expr -- input expression in which the error occurred
        msg  -- explanation of the error
    """
    def __init__(self, expr=None, msg=None):
        self.expr = expr
        self.msg = msg


class PentagonProject():

    availability_zone_designations = list(string.ascii_lowercase)

    def __init__(self, name, args):
        self._repository_name = args.get("repository_name") if args.get("repository_name") else "{}-infrastructure".format(name)

        self._workspace_directory = os.path.expanduser(args.get('workspace_directory'))
        self._project_directory = "{}/projects".format(self._workspace_directory)
        self._venv_directory = "{}/venvs".format(self._workspace_directory)

        self._project_source = os.path.dirname(pentagon.__file__)
        self._name = name
        self._force = args.get('force')
        self._repository_path = "{}/{}/{}".format(
            self._project_directory,
            self._name,
            self._repository_name)

        self._configure_project = args.get('configure')

        self._aws_access_key = args.get('aws_access_key') if args.get('aws_access_key') else '<aws-access-key>'
        self._aws_secret_key = args.get('aws_secret_key') if args.get('aws_secret_key') else '<aws-secret-key>'

        if args.get('aws_default_region'):
            self._aws_default_region = args.get('aws_default_region')
            self._aws_availability_zone_count = int(args.get('aws_availability_zone_count')) if args.get('aws_availability_zone_count') else 3
            self._aws_availability_zones = args.get('aws_availability_zones') if args.get('availability_zones') else self.__default_aws_availability_zones()
        else:
            self._aws_default_region = '<aws-default-region>'
            self._aws_availability_zone_count = args.get('aws_availability_zone_count') if args.get('aws_availability_zone_count') else '<aws_availability_zone_count>'
            self._aws_availability_zones = args.get('aws_availability_zones') if args.get('availability_zones') else '<aws_availability_zones>'

        self._state_store_bucket = args.get('state_store_bucket') if args.get('state_store_bucket') else self._repository_name
        self._git_repo = args.get('git_repo')

        self._create_keys = args.get('create_keys')
        self._ssh_keys = {
                          'admin_vpn': args.get('admin_vpn_key', 'admin-vpn'),
                          'working_kube': args.get('working_kube_key', 'working-kube'),
                          'production_kube': args.get('production_kube_key', 'production-kube'),
                          'working_private': args.get('working_private_key', 'working-private'),
                          'production_private': args.get('production_private_key', 'working-private'),
                         }

        self._working_kubernetes_cluster_name = args.get('working_kubernetes_cluster_name', 'working-1.{}.com'.format(self._name))
        self._working_kubernetes_node_count = args.get('working_kubernetes_node_count', 3)
        self._working_kubernetes_master_aws_zone = args.get('working_kubernetes_master_aws_zone', self._aws_availability_zones[0])
        self._working_kubernetes_master_node_type = args.get('working_kubernetes_master_node_type', 't2.medium')
        self._working_kubernetes_worker_node_type = args.get('working_kubernetes_worker_node_type', 't2.medium')
        self._working_kubernetes_dns_zone = args.get('working_kubernetes_dns_zone', 'working.{}.com'.format(self._name))
        self._working_kubernetes_v_log_level = args.get('working_kubernetes_v_log_level', 10)
        self._working_kubernetes_network_cidr = args.get('working_kubernetes_network_cidr', "172.20.0.0/16")

        self._working_kubernetes_cluster_name = args.get('working_kubernetes_cluster_name', 'production-1.{}.com'.format(self._name))
        self._production_kubernetes_node_count = args.get('production_kubernetes_node_count', 3)
        self._production_kubernetes_master_aws_zone = args.get('production_kubernetes_master_aws_zone', self._aws_availability_zones[0])
        self._production_kubernetes_master_node_type = args.get('production_kubernetes_master_node_type', 't2.medium')
        self._production_kubernetes_worker_node_type = args.get('production_kubernetes_worker_node_type', 't2.medium')
        self._production_kubernetes_dns_zone = args.get('production_kubernetes_dns_zone', 'production.{}.com'.format(self._name))
        self._production_kubernetes_v_log_level = args.get('production_kubernetes_v_log_level', 10)
        self._production_kubernetes_network_cidr = args.get('production_kubernetes_network_cidr', "172.20.0.0/16")

        self._working_kubernetes_cluster_name = args.get('working_kubernetes_cluster_name', 'production-1.{}.com'.format(self._name))
        self._production_kubernetes_cluster_name = args.get('production_kubernetes_cluster_name', 'working-1.{}.com'.format(self._name))

        self._vpc_name = args.get('vpc_name') if args.get('vpc_name') else '<vpc_name>'
        self._vpc_cidr_base = args.get('vpc_cidr_base') if args.get('vpc_cidr_base') else '<vpc_cidr_base>'
        self._vpc_id = args.get('vpc_id') if args.get('vpc_id') else '<vpc_id>'

    def __default_aws_availability_zones(self):
        azs = []
        logging.info("Creating default AWS AZs")
        for i in range(0, self._aws_availability_zone_count):
            azs += ["{}{}".format(self._aws_default_region, self.availability_zone_designations[i])]

        return (", ").join(azs)

    def __project_path_exists(self):
        if os.path.isdir(self._repository_path):
            return True
        return False

    def __delete(self):
            try:
                shutil.rmtree(self._venv_directory+"/"+self._name)
            except OSError, e:
                logging.warn(e)
            try:
                shutil.rmtree(self._project_directory+"/"+self._name)
            except OSError, e:
                logging.warn(e)

    def __git_init(self):
        """ Initialize git repository in the project infrastructure path """
        if self._git_repo:
            return Git().clone(self._git_repo, self._repository_path)
        else:
            return Repo.init(self._repository_path)

    def __run_commands(self, commands):
        logging.debug(commands)
        stdout, stderr = subprocess.Popen(commands,
                                          shell=True,
                                          stdin=subprocess.PIPE,
                                          stdout=subprocess.PIPE,
                                          stderr=subprocess.PIPE).communicate()
        logging.info(stdout)
        logging.error(stderr)
        return (stdout, stderr)

    def __set_virtualenv_env(self):
        os.environ['WORKON_HOME'] = self._venv_directory
        os.environ['PROJECT_HOME'] = self._project_directory
        os.environ['VIRTUALENVWRAPPER_HOOK_DIR'] = "{}/hooks".format(self._workspace_directory)
        os.environ['OMNIA_COOKIECUTTERS'] = "{}/cookiecutters".format(self._workspace_directory)

    def __initialize_virtualenv(self):
        self.__set_virtualenv_env()
        commands = "source /usr/local/bin/virtualenvwrapper.sh; mkproject {}".format(self._name)
        self.__run_commands(commands)

    def __virtual_env_pip_install(self):
        self.__set_virtualenv_env()
        commands = "source /usr/local/bin/virtualenvwrapper.sh; workon {}; pip install -r {}/config/requirements.txt".format(self._name, self._repository_path)
        self.__run_commands(commands)

    def __render_template(self, template_name, template_path, target, context):
        logging.info("Writing {}".format(target))
        logging.debug("Template Context: {}".format(context))
        if os.path.isfile(target):
            logging.warn("Cowardly refusing to overwrite existing file {}".format(target))
            return False

        with open(target, 'w+') as vars_file:
            try:
                template = jinja2.Environment(loader=jinja2.FileSystemLoader(template_path)).get_template(template_name)
                vars_file.write(template.render(context))
            except Exception:
                logging.error("Error writing {}. {}".format(target, sys.exc_info()[0]))
                return False

        logging.debug("Removing {}/{}".format(template_path, template_name))
        os.remove("{}/{}".format(template_path, template_name))

    def __prepare_private_vars(self):
        template_name = "vars.jinja"
        template_path = "{}/config/local".format(self._repository_path)
        target = "{}/config/private/vars".format(self._repository_path)
        context = {'AWS_ACCESS_KEY': self._aws_access_key,
                   'AWS_SECRET_KEY': self._aws_secret_key,
                   'AWS_DEFAULT_REGION': self._aws_default_region}
        return self.__render_template(template_name, template_path, target, context)

    def __prepare_account_vars_sh(self):
        template_name = "vars.sh.jinja"
        template_path = "{}/default/account".format(self._repository_path)
        target = "{}/default/account/vars.sh".format(self._repository_path)
        context = {'KOPS_STATE_STORE_BUCKET': self._state_store_bucket}
        return self.__render_template(template_name, template_path, target, context)

    def __prepare_account_vars_yml(self):
        template_name = "vars.yml.jinja"
        template_path = "{}/default/account".format(self._repository_path)
        target = "{}/default/account/vars.yml".format(self._repository_path)
        context = {'org_name': self._name, 'vpc_name': self._vpc_name}
        return self.__render_template(template_name, template_path, target, context)

    def __prepare_tf_vars(self):
        template_name = "terraform.tfvars.jinja"
        template_path = "{}/default/vpc".format(self._repository_path)
        target = "{}/default/vpc/terraform.tfvars".format(self._repository_path)
        context = {
            'vpc_name': self._vpc_name,
            'vpc_cidr_base': self._vpc_cidr_base,
            'aws_availability_zones': self._aws_availability_zones,
            'aws_availability_zone_count': self._aws_availability_zone_count,
            'aws_region': self._aws_default_region
        }
        return self.__render_template(template_name, template_path, target, context)

    def __prepare_working_kops_vars_sh(self):
        template_name = "vars.sh.jinja"
        template_path = "{}/default/clusters/working/".format(self._repository_path)
        target = "{}/default/clusters/working/vars.sh".format(self._repository_path)
        context = {
            'kubernetes_cluster_name': self._working_kubernetes_cluster_name,
            'aws_availability_zones': re.sub(" ", "", self._aws_availability_zones),
            'vpc_id': self._vpc_id,
            'ssh_key_path': "{}/config/private/{}".format(self._repository_path, self._ssh_keys['working_kube']),
            'kubernetes_node_count': self._working_kubernetes_node_count,
            'kubernetes_master_aws_zone': self._working_kubernetes_master_aws_zone,
            'kubernetes_master_node_type': self._working_kubernetes_master_node_type,
            'kubernetes_worker_node_type': self._working_kubernetes_worker_node_type,
            'kubernetes_dns_zone': self._working_kubernetes_dns_zone,
            'kubernetes_v_log_level': self._working_kubernetes_v_log_level,
            'kubernetes_network_cidr': self._working_kubernetes_network_cidr
        }
        return self.__render_template(template_name, template_path, target, context)

    def __prepare_ssh_config_vars(self):
        template_name = "ssh_config.jinja"
        template_path = "{}/config/local".format(self._repository_path)
        target = "{}/config/local/ssh_config".format(self._repository_path)
        context = {
            'infrastructure_repository': self._repository_path,
            'production_kube_key': self._ssh_keys['production_kube'],
            'working_kube_key': self._ssh_keys['working_kube'],
            'production_private_key': self._ssh_keys['production_private'],
            'working_private_key': self._ssh_keys['working_private'],
            'admin_vpn_key': self._ssh_keys['admin_vpn'],
        }
        return self.__render_template(template_name, template_path, target, context)

    def __prepare_ansible_cfg_vars(self):
        template_name = "ansible.cfg.jinja"
        template_path = "{}/config/local".format(self._repository_path)
        target = "{}/config/local/ansible.cfg".format(self._repository_path)
        context = {
            'infrastructure_repository': self._repository_path,
        }
        return self.__render_template(template_name, template_path, target, context)

    def __create_key(self, name, path, bits=2048):
        key = RSA.generate(bits)

        private_key = "{}{}".format(path, name)
        public_key = "{}{}.pub".format(path, name)

        with open(private_key, 'w') as content_file:
            os.chmod(private_key, 0600)
            content_file.write(key.exportKey('PEM'))

        pubkey = key.publickey()
        with open(public_key, 'w') as content_file:
            content_file.write(pubkey.exportKey('OpenSSH'))

    def start(self):

        if not self.__project_path_exists() or self._force:
            self.__initialize_virtualenv()
            if not self._git_repo:
                logging.info("Copying project files...")
                self.__copy_project_tree()

            if self._configure_project:
                self.__configure_project()
        else:
            raise PentagonException('Project path exists.')

    def initialize_virtualenv(self):
        self.__initialize_virtualenv()

    def configure_project(self):
        self.__configure_project()

    def delete(self):
        self.__delete()

    def __configure_project(self):
        self.__git_init()
        self.__virtual_env_pip_install()

        if not self._git_repo:
            self.__prepare_private_vars()
            self.__prepare_account_vars_sh()
            self.__prepare_account_vars_yml()
            self.__prepare_ssh_config_vars()
            self.__prepare_ansible_cfg_vars()

            if self._create_keys:
                self.__create_keys()

        self.__prepare_tf_vars()

    def __create_keys(self):
            key_path = "{}/config/private/".format(self._repository_path)
            for key in self._ssh_keys:
                key_name = "{}".format(self._ssh_keys[key])
                if not os.path.isfile("{}{}".format(key_path, key_name)):
                    self.__create_key(key_name, key_path)
                else:
                    logging.warn("Key {}{} exits!".format(key_path, key_name))

    def __copy_project_tree(self):
        logging.info(self._project_source)
        logging.info(self._repository_path)
        copytree(self._project_source, self._repository_path, symlinks=True, ignore=ignore_patterns('__init__.py', '*.pyc', 'release.py'))


@click.group()
def cli():
    pass


@click.command()
@click.argument('name')
@click.option('--workspace-directory', default='~/workspace', help='Directory to place new project, defaults to ~/workspace/')
@click.option('--repository-name', help='Name of the folder to initialize the infrastructure repository')
def initialize_virtualenv(name, **kwargs):
    project = PentagonProject(name, kwargs)
    project.initialize_virtualenv()


@click.command()
@click.argument('name')
@click.option('--workspace-directory', default='~/workspace', help='Directory to place new project, defaults to ~/workspace/')
@click.option('--repository-name', help='Name of the folder to initialize the infrastructure repository')
@click.option('--configure/--no-configure', default=True, help='Configure project with default settings')
@click.option('--force/--no-force', help="Ignore existing directories and copy project")
@click.option('--aws-access-key', help="AWS access key")
@click.option('--aws-secret-key', help="AWS secret key")
@click.option('--aws-default-region', help="AWS default region")
@click.option('--aws-availability-zones', help="AWS availability zones as a comma delimited with spaces. Default to region a, region b, ... region z")
@click.option('--aws-availability-zone-count', help="Number of availability zones to use")
@click.option('--state-store-bucket', help="Name of S3 Bucket to store state")
@click.option('--git-repo', help="Existing git repository to clone")
@click.option('--create-keys/--no-create-keys', default=True, help="Ignore existing directories and copy project")
@click.option('--admin-vpn-key', default='admin-vpn', help="Name of the ssh key for the admin user of the VPN instance")
@click.option('--working-kube-key', default='working-kube', help="Name of the ssh key for the working kubernetes cluster")
@click.option('--production-kube-key', default='production-kube', help="Name of the ssh key for the production kubernetes cluster")
@click.option('--working-private-key', default='working-private', help="Name of the ssh key for the working non kubernetes instances")
@click.option('--production-private-key', default='production-private', help="Name of the ssh key for the production non kubernetes instances")
@click.option('--vpc-name', default=datetime.datetime.today().strftime('%Y%m%d'), help="Name of VPC to create")
@click.option('--vpc-cidr-base', default="172.20", help="First two octets of the VPC ip space")
@click.option('--vpc-id', default=None, help="AWS VPC id to create the kubernetes clusters in")
@click.option('--working-kubernetes-cluster-name', help="Name of the working kubernetes cluster nodes")
@click.option('--working-kubernetes-node-count', help="Name of the working kubernetes cluster nodes")

        # self._working_kubernetes_node_count = args.get('working_kubernetes_node_count', 3)
        # self._working_kubernetes_master_aws_zone = args.get('working_kubernetes_master_aws_zone', self._aws_availability_zones[0])
        # self._working_kubernetes_master_node_type = args.get('working_kubernetes_master_node_type', 't2.medium')
        # self._working_kubernetes_worker_node_type = args.get('working_kubernetes_worker_node_type', 't2.medium')
        # self._working_kubernetes_dns_zone = args.get('working_kubernetes_dns_zone', 'working.{}.com'.format(self._name))
        # self._working_kubernetes_v_log_level = args.get('working_kubernetes_v_log_level', 10)
        # self._working_kubernetes_network_cidr = args.get('working_kubernetes_network_cidr', "172.20.0.0/16")


@click.option('--production-kubernetes-cluster-name', default=None, help="Name of the production kubernetes cluster nodes")

@click.option('--vpc-cidr-base', default="172.20", help="First two octets of the VPC ip space")
@click.option('--vpc-cidr-base', default="172.20", help="First two octets of the VPC ip space")

@click.option('--log-level', default="INFO", help="Log Level DEBUG,INFO,WARN,ERROR")
def start_project(name, **kwargs):
    logging.basicConfig(level=kwargs.get('log_level'))
    project = PentagonProject(name, kwargs)
    project.start()
    print next_steps()


@click.command()
@click.argument('name')
@click.option('--workspace-directory', default='~/workspace', help='Directory to place new project, defaults to ~/workspace/')
@click.option('--log-level', default="INFO", help="Log Level DEBUG,INFO,WARN,ERROR")
def delete_project(name, **kwargs):
    logging.basicConfig(level=kwargs.get('log_level'))
    project = PentagonProject(name, kwargs)
    project.delete()


@click.command()
@click.argument('name')
@click.option('--workspace-directory', default='~/workspace', help='Directory to place new project, defaults to ~/workspace/')
@click.option('--repository-name', help='Name of the folder to initialize the infrastructure repository')
@click.option('--aws-access-key', help="AWS access key")
@click.option('--aws-secret-key', help="AWS secret key")
@click.option('--aws-default-region', help="AWS default region")
@click.option('--aws-availability-zones', help="AWS availability zones as a comma delimited with spacesDefault to region a, region b, ... region z")
@click.option('--aws-availability-zone-count', help="Number of availability zones to use")
@click.option('--state-store-bucket', help="Name of S3 Bucket to store state")
@click.option('--git-repo', help="Existing git repository to clone")
@click.option('--create-keys/--no-create-keys', default=True, help="Ignore existing directories and copy project")
@click.option('--admin-vpn-key', default='admin-vpn', help="Name of the ssh key for the admin user of the VPN instance")
@click.option('--working-kube-key', default='working-kube', help="Name of the ssh key for the working kubernetes cluster")
@click.option('--production-kube-key', default='production-kube', help="Name of the ssh key for the production kubernetes cluster")
@click.option('--working-private-key', default='working-private', help="Name of the ssh key for the working non kubernetes instances")
@click.option('--production-private-key', default='production-private', help="Name of the ssh key for the production non kubernetes instances")
@click.option('--vpc-name', default=datetime.datetime.today().strftime('%Y%m%d'), help="Name of VPC to create")
@click.option('--vpc-cidr-base', default="172.20", help="First two octets of the VPC ip space")
@click.option('--log-level', default="INFO", help="Log Level DEBUG,INFO,WARN,ERROR")
def configure_project(name, **kwargs):
    logging.basicConfig(level=kwargs.get('log_level'))
    project = PentagonProject(name, kwargs)
    project.configure_project()


@click.command()
def vpn():
    print "vpn"
    click.echo("VPN")

cli.add_command(start_project, "start-project")
cli.add_command(initialize_virtualenv, "initialize-virtualenv")
cli.add_command(configure_project, "configure-project")
cli.add_command(delete_project, "delete-project")
cli.add_command(vpn)


def next_steps():
    steps = """
workon <project_name>
cd test-infrastructure/default/vpc
source ../account/vars.sh
make plan
#make apply
"""
    return steps

if __name__ == '__main__':
    cli()
